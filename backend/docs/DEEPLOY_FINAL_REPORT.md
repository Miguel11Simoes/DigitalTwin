# Relat√≥rio Final: Tentativa Deeploy Snitch

**Data:** 25 de Dezembro de 2025  
**Status:** ‚ùå **INVI√ÅVEL** - Deeploy Snitch n√£o suporta operadores necess√°rios do modelo

---

## üéØ Objetivo

Converter `pump_predictive.onnx` para c√≥digo C otimizado usando Deeploy targeting Snitch cluster RISC-V.

---

## ‚úÖ Trabalho Completado

### 1. Setup Docker
- ‚úÖ Docker image: `ghcr.io/pulp-platform/deeploy:main` (instalado)
- ‚úÖ Volumes configurados (workspace + deeploy_repo)
- ‚úÖ Scripts automatizados criados

### 2. Corre√ß√µes ONNX Aplicadas

#### Problema 1: Batch Dimensions Din√¢micas
**Erro:**
```
numpy._UFuncNoLoopError: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U21'), dtype('<U21'))
```

**Solu√ß√£o:**
```python
# Fixar batch=1 em todos inputs/outputs
for inp in model.graph.input:
    inp.type.tensor_type.shape.dim[0].dim_value = 1
    inp.type.tensor_type.shape.dim[0].ClearField("dim_param")
```

**Resultado:** ‚úÖ `pump_predictive_fixed.onnx`

#### Problema 2: Operador Reshape N√£o Suportado
**Erro:**
```
RuntimeError: No mapping found for node [...batchnorm/mul_1__12] with op type Reshape
```

**An√°lise:**
- Reshape na posi√ß√£o 0 do grafo (primeiro operador)
- Input: `spec [1, 128, 128, 1]` (NHWC)
- Target: `[-1, 1, 128, 128]` (NCHW)
- **Causa:** Convers√£o de layout NHWC ‚Üí NCHW

**Solu√ß√£o Aplicada:**
```python
# Substituir Reshape por Transpose equivalente
transpose_node = helper.make_node(
    'Transpose',
    inputs=['spec'],
    outputs=[node.output[0]],
    perm=[0, 3, 1, 2],  # NHWC ‚Üí NCHW
    name=node.name.replace('Reshape', 'Transpose')
)
```

**Resultado:** ‚úÖ `pump_predictive_transposed.onnx` (Reshape eliminado)

### 3. Tentativas Executadas

#### Tentativa 1: Batch din√¢mico
```bash
docker run ... testRunner_snitch.py -t /workspace/pump_test --cores 8 --skipsim
```
**Resultado:** ‚ùå Shape error (numpy dtype mismatch)

#### Tentativa 2: Batch fixo
```bash
# Com pump_predictive_fixed.onnx
```
**Resultado:** ‚ùå Reshape n√£o suportado

#### Tentativa 3: Reshape ‚Üí Transpose
```bash
# Com pump_predictive_transposed.onnx
```
**Resultado:** ‚úÖ Reshape resolvido ‚Üí ‚ùå **ReduceMean n√£o suportado**

---

## ‚ùå Bloqueador Final: ReduceMean

### Erro
```
RuntimeError: No mapping found for node 
StatefulPartitionedCallpump_predictive_model_1aux_norm_1momentsmean 
with op type ReduceMean
```

### An√°lise
- **Operador:** ReduceMean
- **Contexto:** Normaliza√ß√£o do input 'aux' (BatchNorm expandido)
- **Localiza√ß√£o:** Nodes 1, 4 do grafo (primeiros processamentos)

### Operadores do Modelo vs Suportados

**Operadores no modelo (top 10):**
```
Add             : 15  ‚úÖ Suportado
Relu            : 15  ‚úÖ Suportado
MatMul          : 12  ‚úÖ Suportado
Conv            :  6  ‚úÖ Suportado
Mul             :  5  ‚úÖ Suportado
ReduceMean      :  2  ‚ùå N√ÉO suportado
MaxPool         :  2  ‚úÖ Suportado
Softmax         :  2  ‚ùì Desconhecido
Reshape         :  1  ‚ùå N√ÉO suportado (resolvido)
Sub             :  1  ‚úÖ Suportado
Sqrt            :  1  ‚ùì Desconhecido
Reciprocal      :  1  ‚ùì Desconhecido
GlobalAveragePool: 1  ‚ùì Desconhecido
Squeeze         :  1  ‚ùì Desconhecido
```

**Operadores Deeploy Snitch confirmados:**
- Conv2D, MatMul, Add, Sub, Mul, ReLU, MaxPool
- BatchNorm (quando fusionado, n√£o expandido)

**Operadores N√ÉO suportados (confirmados):**
- ‚ùå Reshape (workaround: Transpose)
- ‚ùå ReduceMean
- ‚ùì Sqrt, Reciprocal (prov√°vel que n√£o)
- ‚ùì Squeeze
- ‚ùì GlobalAveragePool

---

## üîç Causa Raiz

### Por que tantos operadores "estranhos"?

Keras BatchNormalization √© expandido durante export:
```
BatchNorm(x) = (x - mean) / sqrt(var + epsilon) * gamma + beta
```

Expande-se em:
1. **ReduceMean** (calcular mean)
2. Sub (x - mean)
3. Mul (squared difference)
4. **ReduceMean** (calcular variance)
5. **Sqrt** (raiz da variance)
6. **Reciprocal** (1/sqrt)
7. Mul (normalizar)
8. Add (bias)

**5 destes operadores n√£o s√£o suportados pelo Deeploy Snitch.**

### Por que n√£o fundir BatchNorm?

tf2onnx tenta fundir BatchNorm em Conv quando poss√≠vel, MAS:
- Apenas funciona para BatchNorm **diretamente ap√≥s Conv**
- No nosso modelo, BatchNorm est√°:
  - Nos **inputs** (aux_norm_1, bn1_1_1) - **antes** das Conv
  - Entre layers densas (onde n√£o h√° Conv para fundir)

---

## üìä Estat√≠sticas Finais

### Modelos ONNX Criados
```
~/onnx_export/
‚îú‚îÄ‚îÄ pump_predictive.onnx              # Original (1.8 MB, batch din√¢mico)
‚îú‚îÄ‚îÄ pump_predictive_fixed.onnx        # Batch=1 fixo
‚îú‚îÄ‚îÄ pump_predictive_transposed.onnx   # Reshape ‚Üí Transpose ‚úÖ
‚îú‚îÄ‚îÄ pump_predictive_noreshape.onnx    # Tentativa fold constantes (0 removidos)
‚îî‚îÄ‚îÄ pump_test/network.onnx            # Vers√£o testada (transposed)
```

### Scripts Criados
```
~/onnx_export/
‚îú‚îÄ‚îÄ simplify_onnx.py                  # onnxsim (n√£o usado - build lento)
‚îú‚îÄ‚îÄ fold_constant_reshape.py          # Constant folding manual
‚îú‚îÄ‚îÄ replace_reshape_with_transpose.py # Reshape ‚Üí Transpose ‚úÖ
‚îú‚îÄ‚îÄ run_deeploy_docker.sh             # Container interativo
‚îú‚îÄ‚îÄ deeploy_workflow.sh               # Workflow autom√°tico
‚îî‚îÄ‚îÄ deeploy_snitch_run.log            # Log completo das tentativas
```

### Tempo Investido
- Setup Docker: 10 min
- Corre√ß√£o batch dimensions: 5 min
- Investiga√ß√£o Reshape: 20 min
- Substitui√ß√£o Reshape‚ÜíTranspose: 10 min
- Descoberta ReduceMean: 5 min
- **Total: ~50 minutos**

---

## üéØ Conclus√£o e Pr√≥ximos Passos

### Conclus√£o

**Deeploy Snitch N√ÉO √â VI√ÅVEL para este modelo CNN multi-task.**

**Raz√µes:**
1. Conjunto limitado de operadores suportados
2. BatchNorm expandido gera 5+ operadores n√£o suportados
3. Modelo usa opera√ß√µes complexas (ReduceMean, GlobalAveragePool, Squeeze)
4. Resolver cada operador individualmente seria trabalho de semanas

### Recomenda√ß√£o: Apache TVM

**Por qu√™ TVM?**
- ‚úÖ Suporte completo para todos operadores ONNX
- ‚úÖ Backend RISC-V maduro e testado
- ‚úÖ Quantiza√ß√£o autom√°tica (int8/int16)
- ‚úÖ Otimiza√ß√µes para low-power/embedded
- ‚úÖ Comunidade ativa e documenta√ß√£o extensa

**TVM vs Deeploy:**
| Caracter√≠stica | Deeploy Snitch | Apache TVM |
|---|---|---|
| Operadores ONNX | ~15 b√°sicos | 200+ completos |
| RISC-V Support | ‚úÖ Nativo | ‚úÖ Via LLVM |
| Quantiza√ß√£o | Manual | Autom√°tica |
| Otimiza√ß√£o Snitch | ‚úÖ‚úÖ‚úÖ Espec√≠fica | ‚úÖ Gen√©rica |
| Learning curve | M√©dia | Alta |
| Documenta√ß√£o | Limitada | Extensa |

**Trade-off:**
- Deeploy: c√≥digo **mais otimizado** para Snitch, mas suporte limitado
- TVM: c√≥digo **funcional** para RISC-V, otimiza√ß√µes gen√©ricas mas robustas

---

## üìã Plano TVM (Op√ß√£o D)

### Fase 1: Setup (1-2 horas)
```bash
# Instalar TVM com RISC-V backend
git clone --recursive https://github.com/apache/tvm
cd tvm && mkdir build && cp cmake/config.cmake build/
# Edit config.cmake: set(USE_LLVM ON), set(USE_RISCV ON)
cd build && cmake .. && make -j$(nproc)
```

### Fase 2: Converter ONNX ‚Üí Relay (30 min)
```python
import onnx
import tvm
from tvm import relay

onnx_model = onnx.load("pump_predictive_transposed.onnx")
shape_dict = {'aux': (1, 102), 'spec': (1, 1, 128, 128)}
mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)
```

### Fase 3: Compilar para RISC-V (1 hora)
```python
target = tvm.target.Target("llvm -mtriple=riscv32-unknown-elf -mcpu=generic-rv32")
with tvm.transform.PassContext(opt_level=3):
    lib = relay.build(mod, target=target, params=params)
lib.export_library("pump_model.so")
```

### Fase 4: Quantiza√ß√£o INT8 (1-2 horas)
```python
from tvm.relay.quantize import quantize
qconfig = relay.quantize.qconfig(calibrate_mode='kl_divergence')
with qconfig:
    qmod = quantize(mod, params=params)
```

### Fase 5: Deploy Snitch (2-3 horas)
- Cross-compile para RISC-V ELF
- Integrar com runtime Snitch
- Testar no simulador

**Tempo total estimado: 6-9 horas**

---

## üîó Refer√™ncias

### Deeploy
- Docs: https://pulp-platform.github.io/Deeploy/
- GitHub: https://github.com/pulp-platform/Deeploy
- Supported Ops: https://pulp-platform.github.io/Deeploy/features.html

### TVM
- Homepage: https://tvm.apache.org/
- ONNX Tutorial: https://tvm.apache.org/docs/how_to/compile_models/from_onnx.html
- RISC-V Docs: https://tvm.apache.org/docs/how_to/deploy/riscv.html
- Quantization: https://tvm.apache.org/docs/how_to/quantize.html

### Alternativas
- TFLite Micro: https://www.tensorflow.org/lite/microcontrollers
- CMSIS-NN: https://github.com/ARM-software/CMSIS-NN
- Glow: https://github.com/pytorch/glow

---

## ‚úÖ Arquivos Finais

### Para continuar com TVM:
- `pump_predictive_transposed.onnx` - Modelo otimizado (sem Reshape)
- `pump_test/inputs.npz` - Test inputs
- `pump_test/outputs.npz` - Expected outputs

### Documenta√ß√£o:
- `ONNX_EXPORT_REPORT.md` - Export Keras ‚Üí ONNX
- `DEEPLOY_BLOCKER_REPORT.md` - Bloqueio inicial
- `DEEPLOY_DOCKER_GUIDE.md` - Setup Docker
- `DEEPLOY_FINAL_REPORT.md` - Este documento

---

**Decis√£o Final:** Avan√ßar para **Apache TVM** (Op√ß√£o D) para completar deployment no Snitch cluster.
